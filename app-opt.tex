\chapter{Portfolio-Based Optimization}
\label{app:opt}

The initial focus of my doctoral research
was developing algorithm portfolio strategies
with applications particularly in continuous black-box optimization.
The results of my work have been a software framework for experiments
\citep{cocopf}
and two results published at top-tier conferences \citep{Baudis2014PPSNOnlinePortfolios,Baudis2015GECCO}.
This research had been primarily supervised by Dr. Petr Pošík.

Let us consider the problem of finding a minimum value of a continuous
real-parameter function that has inaccessible analytical form.%
\footnote{No analytical form implies that we do not have information
e.g.\ on the derivatives of the function, except approximating
them numerically.}
This is a rich area of research that produced many algorithms over
the last 50 years --- from the venerable Nelder-Mead simplex
algorithm \citep{NM1} to various gradient descent methods to
population-based methods.

\section{Online Black-box Algorithm Portfolios}

The key question in the face of such variety of optimization
algorithms is ``which algorithm should I choose?''
Unified comparison benchmarks \citep{COCO1}
can help determining the best option for a particular function class.
However, if a function is truly ``black-box'' and its features
are hard to predict, an automated process with minimum overhead
is certainly desirable.

The problem of algorithm selection is not new \citep{Rice}
and was so far popular mainly when applied to
combinatorial problem solvers \citep{combpfsurvey}.
In my work, I adopted the prism of algorithm portfolios \citep{algportfolios}
with \textit{online} selection.%
\footnote{The concept of offline selection also occurs in the literature,
	when we assume a stream of function instances and apply just a single
	algorithm on each of the instances.}
That is, multiple diverse optimization algorithms are applied
to the given function instance simultaneously, with the best
performers quickly gaining the largest time allocation (that is,
the chance to perform the most optimization steps).

Deciding which algorithm to apply in each step of the portfolio
optimization is essentialy an instance of the well-known Multi-Armed
Bandit Problem, where a policy decides which algorithm to try next
based on their empirically determined expected reward.
I have built a modular Python framework \textbf{COCOpf} \citep{cocopf}
suitable both for research and application of this problem.

This helped me to identify fine structure of the problem
(particularly, I proposed a classification of functions based on
their in-portfolio behavior).
Further, I have built a reference portfolio of seven well-known
diverse optimization algorithms and based on performance evaluation
using the popular COCO optimization benchmark \citep{COCO1}, I have
identified a policy that significantly improves the baseline and
on well-behaved functions on average overperforms even the overally
best individual algorithm. This result was presented at the
PPSN 2014 conference. \citep{Baudis2014PPSNOnlinePortfolios}

\section{Minimizing Separable Functions by a Mix of Methods}

Another tier of research on how to best combine different optimization
algorithms concerns speeding up optimization of continuous black-box
\textit{separable} functions in particular.  I have closely cooperated
on this research with my supervisor, Dr. Petr Pošík.

Separable multivariate functions can be decomposed to a sum of univariate
functions, each parametrized solely by a single dimension of the input
vector.
For some very hard separable functions, exploiting separability
is the only way to quickly find the minimum and a natural idea to optimize
such functions is to use univariate optimization algorithms on individual
dimensions.
In \citep{PosikGECCO2009LineSearch}, Brent's method \citep{Brent1973} and the STEP algorithm \citep{STEP} were used to separately optimize the function along each dimension.
Brent's method was shown to be fast in case of unimodal functions, but due to its local nature it fails on multimodal functions.
The global STEP method was able to solve both the uni- and multimodal functions, but needed much larger number of function evaluations.
Moreover, their multidimensional variants were constructed inefficiently: the dimensions were optimized sequentially, one by one.

We have built on the above mentioned methods, and contributed two improvements:

\begin{enumerate}
	\item We combined Brent's method and STEP into a single algorithm which converges faster than STEP (in many cases, it is almost as fast as Brent's method), while it preserves the global search ability of STEP (thus solving a larger proportion of functions than Brent's method, and often doing it faster).

	\item We suggested a better way of making a multidimensional variant of this method. As opposed to solving the 1D problem in all dimensions sequentially, we proposed to interleave the steps in individual dimensions, updating the full coordinates of sampled points based on results obtained in other dimensions so far.%
\footnote{Later, we found out about a similar recent work by Ilya Loschilov \cite{HCMA}, but our algorithm reaches better results.}
\end{enumerate}

Thus, we have introduced a new hybrid algorithm ``Brent-STEP'' combining
these two methods non-trivially and demonstrated that
on univariate and separable functions the hybrid algorithm
in general outperforms both of them,
in the univariate case often by a wide margin,
and that it is behaving robustly even when one of the constituent methods
is failing to converge.
This result was presented at the GECCO 2015 conference.
\citep{Baudis2015GECCO}
